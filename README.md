# Using OpenShift Service Registry with Quarkus and Kafka

This is a copy of the Quickstart application created by [@carlesarnal](https://github.com/redhat-developer/app-services-guides/pull/303) to be used with Red Hat OpenShift Service Registry. 

## Prerequisites

* Free account on [cloud.redhat.com](https://console.redhat.com)
* Java 11
* Maven 3.8.1+
* Git
* [jq](https://stedolan.github.io/jq/)

## Kafka and Service Registry Setup

You need both a Kafka and Service Registry instance prior to running the Quarkus application:

1. Create an free account at [cloud.redhat.com](https://console.redhat.com).
1. Install the [Red Hat OpenShift Application Services CLI](https://github.com/redhat-developer/app-services-guides/tree/main/rhoas-cli#installing-the-rhoas-cli)
1. Login using the CLI:
    ```bash
    rhoas login
    ```
1. Create a free Kafka instance. This will be deleted after 48 hours.
    ```bash
    rhoas kafka create --name quotes-kafka --use
    ```
1. Create a Kafka Topic to hold quote requsets:
    ```bash
    rhoas kafka topic create --name quote-requests
    ```
1. Create a Kafka Topic to hold processed quotes:
    ```bash
    rhoas kafka topic create --name quotes
    ```
1. Create a free Service Registry instance
    ```bash
    rhoas service-registry create --name quotes-sr --use
    ```
1. Create a Service Account. This provides a username (Client ID) and password (Client Secret) to connect to the Kafka and Service Registry instances:
    ```
    rhoas service-account create
    ```

You now have everything you need to start the Quarkus producer application.

## Using the Producer

First you need to set some variables in your session. Then you can start the Quarkus application using Maven:

```bash
# Use the values generated by rhoas service-account create
export CLIENT_ID=<your-client-id>
export CLIENT_SECRET=<your-client-secret>

# Used to connect to and authenticate against the service registry
export OAUTH_SERVER_URL=https://identity.api.openshift.com/auth
export OAUTH_REALM=rhoas
export REGISTRY_URL="$(rhoas service-registry describe | jq .registryUrl -r)/apis/registry/v2"

# Used to connect to and authenticate against the kafka cluster
export BOOTSTRAP_SERVER=$(rhoas kafka describe | jq .bootstrap_server_host -r)
export OAUTH_TOKEN_ENDPOINT_URI=https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token

mvn quarkus:dev -f ./producer/pom.xml -Dquarkus-profile=prod
```

Send a request to the producer using a HTTP client, e.g cURL:

```bash
curl -X POST http://localhost:8080/quotes/request
```

This causes the following to occur:

* The Quarkus application will register the `Quote.avsc` Avro schema to your Service Registry instance via a HTTPS request.
* Service Registry will return the ID of the registered schema in the HTTPS response.
* The Quarkus application will use the Avro schema to serialise the outgoing Quote on the `quote-requests` topic, and include the schema ID in the payload.

Downstream consumers can use the schema ID in the payload to fetch the necessary Avro schema to deserialise and validate incoming data.

## Start the Processing Consumer

Start the consumer/processor using the same environment variables as the producer, but targeting a different POM:

```bash
mvn quarkus:dev -f ./processor/pom.xml -Dquarkus-profile=prod
```
